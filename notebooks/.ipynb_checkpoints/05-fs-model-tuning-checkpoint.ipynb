{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "black-durham",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optical-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funny-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "\n",
    "#Add the scripts directory to the sys path\n",
    "sys.path.append(\"../src/data\")\n",
    "sys.path.append(\"../src/features\")\n",
    "\n",
    "from make_dataset import get_data\n",
    "from data_processor import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "northern-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows and columns in the display\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functional-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expressed-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the train data\n",
    "X_train, y_train = get_data(data_string=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "local-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the test data\n",
    "X_test, y_test = get_data(data_string=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-result",
   "metadata": {},
   "source": [
    "### Baseline Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-vegetable",
   "metadata": {},
   "source": [
    "Lets create a baseline model. In this case, let's say our predicted value is median of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southeast-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(np.zeros(len(y_test)))\n",
    "y_pred[:] = y_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finnish-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06970475324840691"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-liberia",
   "metadata": {},
   "source": [
    "##### Baseline model MAE is 0.0697"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-moses",
   "metadata": {},
   "source": [
    "### Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-crystal",
   "metadata": {},
   "source": [
    "There are more than 500 columns and hence trying different models such as Random Forest, Gradient Boosting, XGBoost will take a lot of time. Hence, lets fix with XGBoost model and hypertune the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-space",
   "metadata": {},
   "source": [
    "#### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wooden-trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.2805\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessor(cols_to_remove=[\"parcelid\", \"propertyzoningdesc\", \"rawcensustractandblock\", \"regionidneighborhood\", \"regionidzip\", \"censustractandblock\"], \n",
    "                  datecol=\"transactiondate\")\n",
    "\n",
    "lin_reg = LinearRegression(n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"dataprocessor\", dp),\n",
    "    (\"lin_reg\", lin_reg)\n",
    "])\n",
    "    \n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"mean absolute error: {0:.4f}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-general",
   "metadata": {},
   "source": [
    "##### Linear Regression MAE is worse than our baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-newport",
   "metadata": {},
   "source": [
    "#### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alien-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.0895\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessor(cols_to_remove=[\"parcelid\", \"propertyzoningdesc\", \"rawcensustractandblock\", \"regionidneighborhood\", \"regionidzip\", \"censustractandblock\"], \n",
    "                  datecol=\"transactiondate\")\n",
    "\n",
    "xgb_reg = xgb.sklearn.XGBRegressor(learning_rate=0.1, n_estimators = 100, objective='reg:squarederror', \n",
    "                                    eval_metric=\"mae\", random_state = 42, verbosity=1, n_thread=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"dataprocessor\", dp),\n",
    "    (\"xgb_reg\", xgb_reg)\n",
    "])\n",
    "    \n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"mean absolute error: {0:.4f}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-charleston",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "flush-provision",
   "metadata": {},
   "source": [
    "Gradient Boosting has the best score among all three models.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-timeline",
   "metadata": {},
   "source": [
    "XGBoost is generally better over Gradient Boosting Model as XGBoost is a regualarized model that controls over fitting and in addition XGBoost is also better in terms of speed and memory utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-invention",
   "metadata": {},
   "source": [
    "Lets find the best XGBoost model using hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfied-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_gridsearch(param_test, xgb_reg):\n",
    "    \n",
    "    dp = DataProcessor(cols_to_remove=[\"parcelid\", \"propertyzoningdesc\", \"rawcensustractandblock\", \"regionidneighborhood\", \"regionidzip\", \"censustractandblock\"], \n",
    "                      datecol=\"transactiondate\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"dataprocessor\", dp),\n",
    "        (\"xgb_reg\", xgb_reg)\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_test, n_jobs=-1, cv=3, verbose=1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"----- Grid Search cv results ----- \\n\")\n",
    "    for mean_score, params in zip(grid_search.cv_results_[\"mean_test_score\"], grid_search.cv_results_[\"params\"]):\n",
    "        print(-(mean_score), params)\n",
    "\n",
    "    print(\"\\n----- Grid Search best parameters ------ \\n\", grid_search.best_params_)\n",
    "    print(\"\\n\")\n",
    "    print(\"----- Grid Search best score ------ \\n\", -(grid_search.best_score_))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-garlic",
   "metadata": {},
   "source": [
    "#### Step 1: Fix learning_rate and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intellectual-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search cv results ----- \n",
      "\n",
      "0.059001987296740964 {'xgb_reg__learning_rate': 0.1}\n",
      "0.12138837303615395 {'xgb_reg__learning_rate': 0.2}\n",
      "0.1974494930753917 {'xgb_reg__learning_rate': 0.3}\n",
      "\n",
      "Grid Search best parameters ------ \n",
      " {'xgb_reg__learning_rate': 0.1}\n",
      "\n",
      "\n",
      "Grid Search best score ------ \n",
      " -0.059001987296740964\n"
     ]
    }
   ],
   "source": [
    "param_test = {\n",
    "    'xgb_reg__learning_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "xgb_reg = xgb.sklearn.XGBRegressor(learning_rate=0.1, n_estimators=1000, max_depth=5, \n",
    "                                    min_child_weight=1, gamma=0, max_delta_step=0, \n",
    "                                    subsample=0.8, colsample_bytree=0.8, colsample_bylevel=1, \n",
    "                                    colsample_bynode=1, reg_lambda=1, reg_alpha=0, \n",
    "                                    scale_pos_weight=1, missing=None, objective='reg:squarederror', \n",
    "                                    eval_metric='mae', seed=0, booster='gbtree')# , silent=0, nthread=-1)\n",
    "\n",
    "xgb_gridsearch(param_test, xgb_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-portfolio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-airfare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-eagle",
   "metadata": {},
   "source": [
    "#### Step 2: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-parker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-petersburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-fiber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-delight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "british-interim",
   "metadata": {},
   "source": [
    "#### Step 3: Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-beach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-dealer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-sweden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "several-proceeding",
   "metadata": {},
   "source": [
    "#### Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-reference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-estonia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "capital-convergence",
   "metadata": {},
   "source": [
    "#### Step 5: Tune regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-damages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
